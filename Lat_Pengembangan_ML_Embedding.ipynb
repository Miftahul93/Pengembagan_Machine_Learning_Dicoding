{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lat Pengembangan ML-Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2DgkBJx+IORnhUSgSyiEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miftahul93/Pengembangan_Machine_Learning_Dicoding/blob/main/Lat_Pengembangan_ML_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFRRobFLPR3c"
      },
      "source": [
        "# **Embedding**\n",
        "Pada klasifikasi teks, kita perlu melakukan embedding yang merupakan kunci dalam klasifikasi teks di Tensorflow. Embedding memungkinkan model ML untuk memahami makna di setiap kata dan mengelompokkan kata-kata dengan makna yang mirip agar berdekatan. Misalnya komentar pada sebuah video youtube, di mana kata-kata “menarik”, “keren”, dan “luar biasa” akan dikelompokkan berdekatan. Pengelompokkan ini dapat dicapai dengan memetakan setiap kata ke dalam vektor atau larik. Di mana kata yang mirip akan memiliki nilai vektor yang mirip. \n",
        "\n",
        "Makna dari sebuah kata didapat dari label dari data tersebut. Misalnya pada teks yang berlabel negatif terdapat banyak kata ‘membosankan’, dan ‘jelek’. Maka kedua kata tersebut memiliki makna yang mirip sehingga nilai vektor mereka mirip. Informasi lebih detail mengenai Embedding dapat Anda lihat pada [tautan](https://www.tensorflow.org/text/guide/word_embeddings) berikut.\n",
        "\n",
        "Untuk mengimplementasikan Embedding pada Keras juga sangatlah mudah. Pada model sequential, kita tinggal memanggil fungsi Embedding() dan mengisi parameter total kata yang di tokenisasi, panjang kalimat, serta dimensi embedding yang diinginkan. Karena hasil dari embedding merupakan larik 2 dimensi yang berisi panjang setiap kalimat, dan dimensi embedding, maka kita memerlukan fungsi flatten()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG1mdgFbP_0k"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(jumlah_kata, dimensi_embedding, pajang_input),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(24, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAyYbs9LWJHa"
      },
      "source": [
        "Setelah mengimplementasikan Embedding pada model sekuensial kita, panggil fungsi compile. Untuk optimizer, kita dapat menggunakan optimizer yang telah kita pelajari sebelumnya. Sedangkan loss disesuaikan dengan kelas yang terdapat pada dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5vsuxtwWI3Z"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metric=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFKyRJTbWfOW"
      },
      "source": [
        "Untuk fungsi fit, kita memerlukan parameter teks yang telah di-padding, label dari data training, jumlah epoch, serta data validasi. Mudah bukan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnmZ56rkWfBd"
      },
      "source": [
        "model.fit(padded_latih, label_latih,\n",
        "          epochs=num_epochs,\n",
        "          validation_data=padded_test, label_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}