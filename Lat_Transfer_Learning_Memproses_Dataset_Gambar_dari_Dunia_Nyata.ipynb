{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lat Transfer Learning-Memproses Dataset Gambar dari Dunia Nyata.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIucQJaBUmF1vmUgB0Qijo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miftahul93/Pengembangan_Machine_Learning_Dicoding/blob/main/Lat_Transfer_Learning_Memproses_Dataset_Gambar_dari_Dunia_Nyata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4rD8R5BdlZG"
      },
      "source": [
        "# **Transfer Learning**\n",
        "Pada masalah computer vision, kesuksesan model yang kita kembangkan secara signifikan dipengaruhi oleh jumlah data yang tersedia. Jumlah data yang sedikit cenderung akan mengakibatkan model kita overfit sehingga prediksi dari model hasilnya tidaklah bagus. Pada submodul sebelumnya kita telah mempelajari salah satu teknik untuk mengatasi jumlah data yang terbatas dengan augmentasi gambar. Selain augmentasi gambar, ada teknik lain yang dapat kita pakai ketika data yang kita miliki untuk pengembangan model terbatas yaitu, transfer learning.\n",
        "\n",
        "Ide dibalik transfer learning untuk masalah computer vision adalah, model yang telah dilatih pada dataset berukuran besar yang berisi gambar umum mampu dipakai sebagai model dasar yang membantu kita untuk mengenali fitur/bentuk-bentuk benda yang terdapat di dunia nyata. Kita dapat memanfaatkan fitur-fitur yang dipelajari ini tanpa harus melakukan pelatihan model dari awal sekali.\n",
        "\n",
        "Sederhananya, transfer learning menggunakan model yang telah dilatih sebelumnya pada dataset lain, untuk dipakai pada dataset kita sendiri. Masih ingat? Layer-layer awal dan di tengah dari sebuah model bertugas untuk mengenali bentuk-bentuk pada gambar. Misalnya pada model pengenalan wajah manusia, pada layer pertama mungkin mengenali garis, layer kedua mengenali lingkaran, layer ketiga mengenali mata, dan layer keempat mampu mengenali wajah. Nah, layer-layer telah dilatih tersebut dapat kita manfaatkan untuk dipakai pada dataset lain misalnya seperti dataset pengenalan ekspresi manusia. \n",
        "\n",
        "Untuk melihat bagaimana efektifnya transfer learning, kita akan belajar menggunakan transfer learning pada dataset cheesman yang kita pelajari pada submodul sebelumnya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KJik-VFHngq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0530aca-a9b2-4328-bbbe-414597f31c4c"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://github.com/dicodingacademy/assets/raw/main/ml_pengembangan_academy/Chessman-image-dataset.zip \\\n",
        "  -O /tmp/Chessman-image-dataset.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-03 10:05:45--  https://github.com/dicodingacademy/assets/raw/main/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dicodingacademy/assets/main/ml_pengembangan_academy/Chessman-image-dataset.zip [following]\n",
            "--2021-08-03 10:05:46--  https://raw.githubusercontent.com/dicodingacademy/assets/main/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60684125 (58M) [application/zip]\n",
            "Saving to: ‘/tmp/Chessman-image-dataset.zip’\n",
            "\n",
            "/tmp/Chessman-image 100%[===================>]  57.87M   215MB/s    in 0.3s    \n",
            "\n",
            "2021-08-03 10:05:48 (215 MB/s) - ‘/tmp/Chessman-image-dataset.zip’ saved [60684125/60684125]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgaLHLBeH8xh"
      },
      "source": [
        "Kemudian, kita buat direktori untuk dataset kita untuk digunakan pada ImageDataGenerator. Pada ImageDataGenerator gunakan augmentasi yang sama dengan latihan pada submodul sebelumnya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijRTjllLICTN"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "local_zip = '/tmp/Chessman-image-dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "train_dir = os.path.join('/tmp/Chessman-image-dataset/Chess')\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=20,\n",
        "                                   zoom_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   fill_mode = 'nearest',\n",
        "                                   validation_split=0.1) # Set validation split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ult8Z8LaZ3g-"
      },
      "source": [
        "Bagi dataset menjadi data training dan data validasi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4ATMgRnZ3Al",
        "outputId": "8fc73167-ce28-4e17-8676-34cae3567037"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical',\n",
        "    subset='training') # set as training data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, # same directory as training data\n",
        "    target_size=(150,150),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 499 images belonging to 6 classes.\n",
            "Found 52 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYRjPL2DZ2tv"
      },
      "source": [
        "Nah, disini kita mulai mengimplementasikan transfer learning. Untuk model yang kita pilih sebagai model dasar transfer learning adalah ResNet152V2. Model ResNet152V2 memiliki sebanyak 152 layer dan tersedia di library keras. Kita dapat memanfaatkan fitur-fitur yang telah dipelajari oleh model tersebut untuk dipakai model kita. \n",
        "\n",
        "Untuk mengimplementasikan transfer learning sangatlah mudah seperti kode di bawah. Kita hanya perlu menambahkan 2 buah baris kode berbeda. Layer pertama pada model kita adalah model yang kita pakai untuk transfer learning. Kita cukup memanggil kelas ResNet152V2 dan mengisi parameter sebagai berikut:\n",
        "\n",
        "\n",
        "* Weight : ini adalah bobot atau parameter seperti yang telah dibahas pada kelas machine learning pemula. Untuk parameter weight kita mengisi nilai ‘imagenet’. Artinya kita ingin menggunakan model ResNet152V2 yang telah dilatih pada dataset imagenet. Imagenet adalah sebuah database raksasa yang berisi lebih dari 14 juta gambar.\n",
        "* Include_top : parameter ini bernilai boolean. Maksud dari parameter ini apabila kita ingin tetap memakai layer terakhir/layer prediksi dari model resnet. Kita isi false karena kita memakai model resnet untuk memprediksi dataset chessman bukan imagenet.\n",
        "* Input_tensor : sesuai namanya parameter ini menspesifikasikan ukuran dari input.\n",
        "\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtncwopYi8HB"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  ResNet152V2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(150, 150, 3))),\n",
        "  # tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CkRtoIzmiv5"
      },
      "source": [
        "Lanjutkan dengan menentukan optimizer, loss, serta metrik yang ingin digunakan pada model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnO6EUCgmt-T"
      },
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikkrR20NnOBK"
      },
      "source": [
        "Terakhir kita dapat melakukan pelatihan model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuG6Fkg6nO9R",
        "outputId": "465b2cbd-810c-43ae-92f0-488a826a91c3"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    validation_data = validation_generator,\n",
        "                    epochs=50,\n",
        "                    verbose=2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "63/63 - 52s - loss: 7.5872 - accuracy: 0.4409 - val_loss: 2.6770 - val_accuracy: 0.5769\n",
            "Epoch 2/50\n",
            "63/63 - 12s - loss: 1.7167 - accuracy: 0.6834 - val_loss: 0.8976 - val_accuracy: 0.7885\n",
            "Epoch 3/50\n",
            "63/63 - 12s - loss: 0.9207 - accuracy: 0.7715 - val_loss: 1.5894 - val_accuracy: 0.6538\n",
            "Epoch 4/50\n",
            "63/63 - 11s - loss: 1.0627 - accuracy: 0.7615 - val_loss: 1.7339 - val_accuracy: 0.6154\n",
            "Epoch 5/50\n",
            "63/63 - 11s - loss: 0.9478 - accuracy: 0.7876 - val_loss: 1.0475 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "63/63 - 11s - loss: 0.6471 - accuracy: 0.8457 - val_loss: 1.3508 - val_accuracy: 0.6731\n",
            "Epoch 7/50\n",
            "63/63 - 12s - loss: 0.6389 - accuracy: 0.8377 - val_loss: 1.0652 - val_accuracy: 0.6923\n",
            "Epoch 8/50\n",
            "63/63 - 12s - loss: 0.7482 - accuracy: 0.8417 - val_loss: 0.7885 - val_accuracy: 0.7692\n",
            "Epoch 9/50\n",
            "63/63 - 11s - loss: 0.6092 - accuracy: 0.8377 - val_loss: 1.2058 - val_accuracy: 0.7308\n",
            "Epoch 10/50\n",
            "63/63 - 11s - loss: 0.3698 - accuracy: 0.8898 - val_loss: 1.0638 - val_accuracy: 0.7692\n",
            "Epoch 11/50\n",
            "63/63 - 11s - loss: 0.2654 - accuracy: 0.9259 - val_loss: 1.3072 - val_accuracy: 0.8269\n",
            "Epoch 12/50\n",
            "63/63 - 11s - loss: 0.4129 - accuracy: 0.9158 - val_loss: 0.9008 - val_accuracy: 0.8269\n",
            "Epoch 13/50\n",
            "63/63 - 12s - loss: 0.5515 - accuracy: 0.8717 - val_loss: 0.5789 - val_accuracy: 0.7885\n",
            "Epoch 14/50\n",
            "63/63 - 12s - loss: 0.3232 - accuracy: 0.9158 - val_loss: 1.2180 - val_accuracy: 0.8077\n",
            "Epoch 15/50\n",
            "63/63 - 11s - loss: 0.3495 - accuracy: 0.9118 - val_loss: 1.5787 - val_accuracy: 0.6923\n",
            "Epoch 16/50\n",
            "63/63 - 11s - loss: 0.4516 - accuracy: 0.8998 - val_loss: 1.3699 - val_accuracy: 0.7115\n",
            "Epoch 17/50\n",
            "63/63 - 11s - loss: 0.3815 - accuracy: 0.9038 - val_loss: 0.8352 - val_accuracy: 0.7692\n",
            "Epoch 18/50\n",
            "63/63 - 11s - loss: 0.2467 - accuracy: 0.9279 - val_loss: 1.3975 - val_accuracy: 0.7308\n",
            "Epoch 19/50\n",
            "63/63 - 12s - loss: 0.3913 - accuracy: 0.9218 - val_loss: 0.8453 - val_accuracy: 0.8462\n",
            "Epoch 20/50\n",
            "63/63 - 12s - loss: 0.2628 - accuracy: 0.9218 - val_loss: 0.6517 - val_accuracy: 0.8654\n",
            "Epoch 21/50\n",
            "63/63 - 11s - loss: 0.5060 - accuracy: 0.9178 - val_loss: 1.6135 - val_accuracy: 0.7115\n",
            "Epoch 22/50\n",
            "63/63 - 11s - loss: 0.3754 - accuracy: 0.9158 - val_loss: 0.8786 - val_accuracy: 0.7885\n",
            "Epoch 23/50\n",
            "63/63 - 11s - loss: 0.2740 - accuracy: 0.9359 - val_loss: 1.3549 - val_accuracy: 0.7308\n",
            "Epoch 24/50\n",
            "63/63 - 11s - loss: 0.2840 - accuracy: 0.9339 - val_loss: 1.8821 - val_accuracy: 0.7115\n",
            "Epoch 25/50\n",
            "63/63 - 12s - loss: 0.3573 - accuracy: 0.9238 - val_loss: 1.4192 - val_accuracy: 0.7308\n",
            "Epoch 26/50\n",
            "63/63 - 12s - loss: 0.3593 - accuracy: 0.9238 - val_loss: 1.2215 - val_accuracy: 0.7885\n",
            "Epoch 27/50\n",
            "63/63 - 11s - loss: 0.2304 - accuracy: 0.9559 - val_loss: 1.5167 - val_accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "63/63 - 12s - loss: 0.4358 - accuracy: 0.9118 - val_loss: 0.9611 - val_accuracy: 0.7885\n",
            "Epoch 29/50\n",
            "63/63 - 11s - loss: 0.3050 - accuracy: 0.9279 - val_loss: 0.8149 - val_accuracy: 0.8846\n",
            "Epoch 30/50\n",
            "63/63 - 11s - loss: 0.2356 - accuracy: 0.9459 - val_loss: 0.6369 - val_accuracy: 0.8077\n",
            "Epoch 31/50\n",
            "63/63 - 11s - loss: 0.0992 - accuracy: 0.9619 - val_loss: 0.7055 - val_accuracy: 0.8462\n",
            "Epoch 32/50\n",
            "63/63 - 11s - loss: 0.1687 - accuracy: 0.9559 - val_loss: 1.0190 - val_accuracy: 0.8269\n",
            "Epoch 33/50\n",
            "63/63 - 11s - loss: 0.1543 - accuracy: 0.9519 - val_loss: 0.6962 - val_accuracy: 0.7885\n",
            "Epoch 34/50\n",
            "63/63 - 12s - loss: 0.1195 - accuracy: 0.9699 - val_loss: 0.9631 - val_accuracy: 0.7692\n",
            "Epoch 35/50\n",
            "63/63 - 11s - loss: 0.1314 - accuracy: 0.9739 - val_loss: 0.9195 - val_accuracy: 0.7692\n",
            "Epoch 36/50\n",
            "63/63 - 11s - loss: 0.1523 - accuracy: 0.9559 - val_loss: 0.6118 - val_accuracy: 0.8269\n",
            "Epoch 37/50\n",
            "63/63 - 11s - loss: 0.0781 - accuracy: 0.9719 - val_loss: 0.9582 - val_accuracy: 0.7885\n",
            "Epoch 38/50\n",
            "63/63 - 11s - loss: 0.1796 - accuracy: 0.9539 - val_loss: 2.2243 - val_accuracy: 0.6346\n",
            "Epoch 39/50\n",
            "63/63 - 12s - loss: 0.3699 - accuracy: 0.9198 - val_loss: 1.5004 - val_accuracy: 0.6923\n",
            "Epoch 40/50\n",
            "63/63 - 12s - loss: 0.1981 - accuracy: 0.9639 - val_loss: 1.0862 - val_accuracy: 0.7308\n",
            "Epoch 41/50\n",
            "63/63 - 11s - loss: 0.1577 - accuracy: 0.9639 - val_loss: 1.3346 - val_accuracy: 0.8077\n",
            "Epoch 42/50\n",
            "63/63 - 11s - loss: 0.2897 - accuracy: 0.9599 - val_loss: 1.4509 - val_accuracy: 0.7885\n",
            "Epoch 43/50\n",
            "63/63 - 11s - loss: 0.2372 - accuracy: 0.9539 - val_loss: 0.5816 - val_accuracy: 0.8462\n",
            "Epoch 44/50\n",
            "63/63 - 12s - loss: 0.1003 - accuracy: 0.9780 - val_loss: 0.6392 - val_accuracy: 0.8462\n",
            "Epoch 45/50\n",
            "63/63 - 12s - loss: 0.0836 - accuracy: 0.9739 - val_loss: 0.9191 - val_accuracy: 0.7885\n",
            "Epoch 46/50\n",
            "63/63 - 12s - loss: 0.1526 - accuracy: 0.9719 - val_loss: 0.6750 - val_accuracy: 0.7692\n",
            "Epoch 47/50\n",
            "63/63 - 11s - loss: 0.2359 - accuracy: 0.9739 - val_loss: 1.1670 - val_accuracy: 0.8077\n",
            "Epoch 48/50\n",
            "63/63 - 11s - loss: 0.1326 - accuracy: 0.9659 - val_loss: 1.6146 - val_accuracy: 0.7692\n",
            "Epoch 49/50\n",
            "63/63 - 11s - loss: 0.0777 - accuracy: 0.9800 - val_loss: 1.5084 - val_accuracy: 0.7692\n",
            "Epoch 50/50\n",
            "63/63 - 12s - loss: 0.1209 - accuracy: 0.9699 - val_loss: 1.0153 - val_accuracy: 0.8269\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}